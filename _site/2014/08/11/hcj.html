<!DOCTYPE html>
<head>
  <meta http-equiv="Content-type" content="text/html; charset=utf-8">
  <meta name="google-site-verification" content="H6k1xpusWugwaQgJsWDpiTw4J_AGFZHR4shRsOvPI78" />
  <meta name="viewport" content="width=device-width, initial-scale=1">
  <link rel="stylesheet" href="https://unpkg.com/purecss@1.0.0/build/pure-min.css" integrity="sha384-nn4HPE8lTHyVtfCBi5yW9d20FjT8BJwUXyWZT9InLYax14RDjBj46LmSztkmNP9w" crossorigin="anonymous">
  <link rel="stylesheet" href="https://unpkg.com/purecss@1.0.0/build/grids-responsive-min.css">
  <link rel="stylesheet" href="/stylesheets/style.css">
  <link rel="stylesheet" href="/stylesheets/pygment_github.css">
  <title>Hadoop Conference Japan 2014 に行ってきて感じた事まとめ</title>
</head>
<body>
  <div class="pure-g">
    <div class="pure-u-1 pure-u-md-1">
      <header role='banner'>
        <h1 class="blog-title">包丁一本さらしに巻いて</h1>
        <nav role='navigation'>
          <div class="pure-menu pure-menu-horizontal">
            <ul class="pure-menu-list">
              <li class="pure-menu-item"><a href="/" class="pure-menu-link">Top</a></li>
              <li class="pure-menu-item"><a href="/about.html" class="pure-menu-link">About</a></li>
              <li class="pure-menu-item"><a href="https://speakerdeck.com/achiku" class="pure-menu-link">Slide</a></li>
              <li class="pure-menu-item"><a href="/feed.xml" class="pure-menu-link">Feed</a></li>
            </ul>
          </div>
        </nav>
      </header>
    </div>
    <div class="pure-u-1 pure-u-md-1">
      <article class="text">
        <script type="text/javascript">
var disqus_shortname = 'achiku';

(function () {
    var s = document.createElement('script'); s.async = true;
    s.type = 'text/javascript';
    s.src = '//' + disqus_shortname + '.disqus.com/count.js';
    (document.getElementsByTagName('HEAD')[0] || document.getElementsByTagName('BODY')[0]).appendChild(s);
}());
</script>

<div id="fb-root">
<script>
  window.fbAsyncInit = function() {
    // init the FB JS SDK
    FB.init({
      appId      : '1447639612119183',                   // App ID from the app dashboard
      status     : true,                                 // Check Facebook Login status
      xfbml      : true                                  // Look for social plugins on the page
    });

    // Additional initialization code such as adding Event Listeners goes here
  };

  // Load the SDK asynchronously
  (function(){
     // If we've already installed the SDK, we're done
     if (document.getElementById('facebook-jssdk')) {return;}

     // Get the first script element, which we'll use to find the parent node
     var firstScriptElement = document.getElementsByTagName('script')[0];

     // Create a new script element and set its id
     var facebookJS = document.createElement('script'); 
     facebookJS.id = 'facebook-jssdk';

     // Set the new script's source to the source of the Facebook JS SDK
     facebookJS.src = '//connect.facebook.net/en_US/all.js';

     // Insert the Facebook JS SDK into the DOM
     firstScriptElement.parentNode.insertBefore(facebookJS, firstScriptElement);
   }());
</script>
</div>
<script>(function(d, s, id) {
  var js, fjs = d.getElementsByTagName(s)[0];
  if (d.getElementById(id)) return;
  js = d.createElement(s); js.id = id;
  js.src = "//connect.facebook.net/en_US/all.js#xfbml=1&appId=1447639612119183";
  fjs.parentNode.insertBefore(js, fjs);
}(document, 'script', 'facebook-jssdk'));</script>

<div>
    <h3>Hadoop Conference Japan 2014 に行ってきて感じた事まとめ</h3>
    <p>2014.08.11</p>
</div>
<div>
    <p>さる2014/07/08、Hadoop Conference Japan 2014が開催されました。1ヶ月以上もアウトプットできなかった理由はおいといて、基調講演には出れていないのだけれど、いくつか回ったセッションを総合して、感じた事をまとめておきたいと思います。前提として、自分はHadoopの素人且つエンジニア1年目なので、鋭いマサカリ投げられると失禁したまま気絶する事が予想されますが、事実と異なる事書いてしまっていたり、それちがうんじゃねーのか、的な指摘は是非コメントください！間違ってる事書いておくの嫌ですし、他の人達がどう考えているのか知りたいです。</p>

<h2 id="見て回ったセッション">見て回ったセッション</h2>

<ul>
  <li>SQLによるバッチ処理とストリーム処理 <a href="http://www.slideshare.net/tagomoris/hcj2014-sql">資料</a></li>
  <li>A Deeper Understanding of Spark Internals <a href="http://www.slideshare.net/hadoopconf/japanese-spark-internalssummit20143">資料</a></li>
  <li>Spark1.0での動作検証 - Hadoopユーザ・デベロッパから見たSparkへの期待 <a href="http://www.slideshare.net/hadoopxnttdata/apache-spark-nttdatahcj2014">資料</a></li>
  <li>Evolution of Impala - Hadoop 上の高速SQLエンジン、最新情報 <a href="http://www.slideshare.net/Cloudera_jp/evolution-of-impala-hcj2014">資料</a></li>
  <li>並列SQLエンジンPresto - 大規模データセットを高速にグラフ化する方法 <a href="http://www.slideshare.net/frsyuki/presto-hadoop-conference-japan-2014">資料</a></li>
</ul>

<h2 id="思ったこと">思ったこと</h2>

<p>このカンファレンスに出て思ったことが3つある。</p>

<ul>
  <li>「大規模データ処理」という言葉の細分化</li>
  <li>SQL系のDSLが支配的になってきてる背景</li>
  <li>リアルタイムデータ処理の先にあるもの</li>
</ul>

<p>これら思ったことについて順にまとめていく。</p>

<h2 id="大規模データ処理という言葉の細分化">「大規模データ処理」という言葉の細分化</h2>

<p>今回一連のセッションを聞いていて一番深く感じ入ったのは、タゴモリさんの公演「SQLによるバッチ処理とストリーム処理」に出てきた分類表。</p>

<iframe src="//www.slideshare.net/slideshow/embed_code/36733256?startSlide=29" width="427" height="356" frameborder="0" marginwidth="0" marginheight="0" scrolling="no" style="border:1px solid #CCC; border-width:1px 1px 0; margin-bottom:5px; max-width: 100%;" allowfullscreen=""> </iframe>
<div style="margin-bottom:5px"> <strong> <a href="https://www.slideshare.net/tagomoris/hcj2014-sql" title="Batch processing and Stream processing by SQL" target="_blank">Batch processing and Stream processing by SQL</a> </strong> from <strong><a href="http://www.slideshare.net/tagomoris" target="_blank">SATOSHI TAGOMORI</a></strong> </div>

<p>大規模なデータを処理している人たちにとってみたらもはやあたりまえの事なのかもしれないですが、自分の中でこのような分類がなされていなかったため、今後何をどこで使っていくのか、ということを考える際に凄い参考になりました。</p>

<p>####Batch</p>

<p>少し前の時代、大量のデータに対して実行される高いレイテンシを持つ処理(週単位、月単位とか)を、安全確実/自動リカバリ付きでコモディティHW上でも実行できるYARNベースの夜間バッチが「所謂大規模データ処理」のメインストリームだったように思えます。(YARNベース、ちょっと言葉おかしいかもしれないけど、リソース管理、スケジューリング、投機的実行を管理しているのがYARNなのでHiveもJavaやその他言語で書いたMapReduceも含む)。そこで集計されたサマリ値をRDBMSに投入し、日別の実績推移を確認できる。これで今までRDBMSで処理していたバッチ処理というものを、より速く確実にスケールする構成で実行できるようになっていった。これが表のBatch部分。</p>

<p>####Short Batch (Interactive Query)</p>

<p>次はShort Batch部分。時代は移り変わり「既存RDBMSで捌ききれなかったような大量データを安全確実に集計処理できる」から一歩進んで「既存RDBMSで捌ききれなかったような大量データを、軽快に、エンジニア以外の人が分析したい」という要望が発生してきている。至極当然な流れで、結局大量のデータを処理するのは、膨大なファクトから商売に対する示唆を得て実際の施策成功精度向上/仮説検証プロセスの高速化であり、事実から示唆を絞り出すのはエンジニアよりも現場で商売を回している人達の方がその商売独自の勘所もある。こういった要望に対して、Hadoopで集計してRDBMSに入れて、というプロセスで対応出来ないことも無い。対応出来ないことも無いけど、ちょっと想定と異なる軸で見ようとすると新規集計バッチを作らなければいけなくなったり、例えばささっと作ったHiveQLを作って流さないといけなかったりする(流石にアドホックにMapReduceを書く事はあまり無いような気がする)。そうなると、Hiveはもともと高いレイテンシ向けの処理用に作られており、JVMの起動、リソース確保、スケジューリング、MapReduceアルゴリズムへの変換、等の処理で起動/実行のオーバーヘッド大きいため、インタラクティブに示唆を！という要望にはあんまりマッチしなかったりするように思う。shibとかがこの領域で頑張っていた雰囲気。</p>

<p>上記のような若干無茶な要望に対応するようにMPP(Massively Parallel Processing)系のクエリエンジンが勃興してきている。始祖はGoogleが2010年に出した<a href="http://research.google.com/pubs/pub36632.html">Dremel: Interactive Analysis of Web-Scale Datasets</a>という論文。この辺りをオープンソースで実装したプロダクトで有名なのがImpala。なぜHiveではないのか、なぜImpalaを作ろうと思ったのか、その辺りの歴史の変遷はCouderaさんの<a href="http://www.cloudera.co.jp/blog/20140107-impala-v-hive.html">この記事</a>に詳しく書いてあり大変勉強になりました。MapReduceを利用せず、Hadoopコンポーネントが提供するYARNを利用せず、だがしかし分散ストレージHDFSとHiveの既存DDLは有効活用し、よりインタラクティブなクエリを実行できるようなプロダクトになっている。その他にもMPP系エンジン括りでいくと、Presto、Apache Drill等が代表選手。特にPrestoはその出生の原因がこの、「エンジニアが頑張らなくてもインタラクティブに分析したい欲」をよく表しており、やっぱエンジニア以外がサクサク分析できてなんぼ感がある。<a href="http://www.publickey1.jp/blog/13/facebooksqlprestomapreducehive10.html">Facebook、分散SQLエンジン「Presto」公開。大規模データをMapReduce/Hiveの10倍効率よく処理すると</a></p>

<p>(ただ、高レイテンシ向けに設計されたHadoop上のHiveと低レイテンシを狙ったImpala/Presto/Drillを比較して10倍効率が良いって言うのには若干抵抗がある。みんなちがって、みんないい、と言いたい。)</p>

<p>正直Short BatchよりもInteractive Queryingという言葉の方が自分的にはしっくりきている。MPPエンジンはrepeatedlyさんがまとめているこの記事が最高にまとまってて参考になる。</p>

<p><a href="http://repeatedly.github.io/ja/2014/07/mpp-on-hadoop-redshift-bigquery/">MPP on Hadoop, Redshift, BigQuery</a></p>

<p>####Stream Processing</p>

<p>最後に表のStream部分。これはInteractive Queryより更に踏み込んでおり、自分もまだ手元に環境作って試せていないのですが、Streamとして送られてくるデータをストレージに書き込む前に集計してしまう代物らしい。ニアリアルタイムとか、5分毎のバッチ、そういう甘い話ではなく、流れてくるデータがストレージに書き込まれる前に集計されて記録される。そしてタゴモリさんが作っているNorikraは、集計の記述にSQLライクな言語を利用できるという。</p>

<p>すごい未来感(小並)。</p>

<p>ただ、商売に直結するか否かに関しては、自分の中でまだ疑問も残っている(詳細後述)。LINEさんでは小さいバジェットで広告を配信した際でもリアルタイムで集計できていれば、追加で枠を買ったり等の判断を行える為便利だ、という話をされていた。</p>

<p>あと印象に残った言葉は、「再実行が難しい」という部分。確かにリアルタイムで、データがPersistentな形になる前に集計しているので、コケた際に再度集計っていうのが難しそう。</p>

<p><strong>Batch</strong>, <strong>Interactive Query</strong>, <strong>Stream Processing</strong>という、今まで「大規模データ処理」で一括りにされていた部分が細分化され、それぞれの領域で活躍できるソフトウェアがある、用途に合わせて選ぶべし、というのは多分今回のカンファレンスで一番響いた部分。</p>

<p>次。</p>

<h2 id="sql系のdslが支配的になってきてる背景">SQL系のDSLが支配的になってきてる背景</h2>

<p>コレはやっぱり感じた。Norikraもそうだけど、ImpalaもPrestoもSQL。Sparkも今までのプログラミングモデル(メソッドチェーン的なヤツ)からSQL系のDSLに乗り換えていく、という話をされていた。<a href="http://www.infoq.com/jp/news/2014/04/databricks-spark-sql">DataBricks，Sparkで構造化データを操作するSpark SQLを発表</a></p>

<p>これはなんとなく、納得がいく気がしている。たぶん以下三点。</p>

<ul>
  <li>既存知識流用できる(次々出てくるDSLに脳味噌を対応させていくより、既に有る脳内のモデルを再利用できる方が客はつく気がする。客とはこの場合ソフトウェアのユーザを意味する。)</li>
  <li>宣言的記述のできる言語はとりあえず楽(データを取得する為の手続き/集計の最適化やEventual Consistentとか考えながらよりも、宣言的に欲しいデータの形だけ描いて、あとはオプティマイザに任せる、っていうのが楽。そこまで甘くはないけど、でも無いより全然楽。)</li>
  <li>ビジネスサイドももっとデータ弄りたい(なにげにコレが一番でかいのではないかという気がする。仮説を立てるのも、検証するのもビジネスサイドで実施することが多いし、彼らが自分たちで集計できれば、エンジニアサイドとのコミュニケーションコストも下がる。)</li>
</ul>

<p>自分はSQLかなり好きなのでこの流れは個人的に嬉しいです。</p>

<h2 id="リアルタイムデータ処理の先にあるもの">リアルタイムデータ処理の先にあるもの</h2>

<p>ココは本当に未来な感じだし、自分もまだよく考えが練れていない。</p>

<p>システムの異常監視、とある条件を設定した閾値を超えた場合通知とかには多分凄いマッチする気がする。条件設定した以上のエラーが吐かれていたら通知、スケールアウトする、とか。</p>

<p>ただ、若干抽象的になってしまうけど、「人間の意思決定」がどこかに挟まるとその力は途端に弱くなってしまうな、という印象。人間の意思決定、もう少し踏み込むと「会社の意思決定」というのはやはり時間がかかるため、5分に1回でいいのでは、という素朴な疑問が出てきてしまう。</p>

<p>先ほどのシステム監視の例は自分がプログラムを書く側だからすっと思いつく例なのかもしれない。もしかしたらビジネスサイドの人々にこういう機構もあるよ、という話をしたらリアルタイムデータ処理が力を発揮する場所を思いつくのかも。</p>

<p>今自分が会社で扱っている商売の範囲だと、「在庫(枠)と広告(CPM, CPC, CPM)の全体的なポートフォリオをリアルタイムで最適化していけるから最高の利益を出せるんです」的な領域では力を発揮しそう。いくらで買ったどの枠にどういう属性を持っている人が来た時にこの広告を出す、というのを決めるパラメタを、リアルタイムで実績を反映させて更新し続けていく仕組み。DSPでもリアルタイムに「どの広告をビットレスポンスとして返すのか」を決める内部的なパラメタにフィードバックを行っているのだろうか。DSPの仕組みはなんとなく把握しているけど、かの仕組みにリアルタイムに何かを集計して得になる部分をしっかりイメージできない。修行不足である。</p>

<p>こういった仕組を、SQLライクなDSLを持ったStream Processing系ソフトウェアを使う事でより柔軟にできるのでは、という仮説はある。</p>

<p>「人間の意思決定」を挟まないところには非常に有効だが、リアルタイムに集計されるグラフを見て人がその場で値千金の意思決定を秒速でする、というのは、どうもあまりしっくり来てない。しっくりきてないんだけど、この領域はまだ見ぬ応用方法が色々ありそうでとっても面白そうだなーー、と思いながら新橋から帰りました。</p>

<h2 id="まとめ">まとめ</h2>

<p>最後になりますが、一ヶ月も経ってなんだよ、という感じではありますが、会場の準備をしてくださった方々、公演してくださった方々、本当にありがとうございました！あの大規模なカンファレンスが無料という奇跡、本当に凄いです。</p>

</div>
<div class="post-sharing">
  <a href="https://twitter.com/share" class="twitter-share-button" data-via="_achiku" style="display: inline-block; vertical-align: bottom;">Tweet</a>
  <script>!function(d,s,id){var js,fjs=d.getElementsByTagName(s)[0],p=/^http:/.test(d.location)?'http':'https';if(!d.getElementById(id)){js=d.createElement(s);js.id=id;js.src=p+'://platform.twitter.com/widgets.js';fjs.parentNode.insertBefore(js,fjs);}}(document, 'script', 'twitter-wjs');</script>
  <a class="fb-like" data-href="" data-layout="button_count" data-action="like" data-show-faces="true" data-share="true" style="display: inline-block"></a>
</div>
<div id="disqus_thread"></div>
<script type="text/javascript">
    /* * * CONFIGURATION VARIABLES: EDIT BEFORE PASTING INTO YOUR WEBPAGE * * */
    var disqus_shortname = 'achiku'; // required: replace example with your forum shortname

    /* * * DON'T EDIT BELOW THIS LINE * * */
    (function() {
        var dsq = document.createElement('script'); dsq.type = 'text/javascript'; dsq.async = true;
        dsq.src = '//' + disqus_shortname + '.disqus.com/embed.js';
        (document.getElementsByTagName('head')[0] || document.getElementsByTagName('body')[0]).appendChild(dsq);
    })();
</script>
<noscript>Please enable JavaScript to view the <a href="http://disqus.com/?ref_noscript">comments powered by Disqus.</a></noscript>
<a href="http://disqus.com" class="dsq-brlink">comments powered by <span class="logo-disqus">Disqus</span></a>

      </article>
    </div>
    <script>
      (function(i,s,o,g,r,a,m){i['GoogleAnalyticsObject']=r;i[r]=i[r]||function(){
      (i[r].q=i[r].q||[]).push(arguments)},i[r].l=1*new Date();a=s.createElement(o),
      m=s.getElementsByTagName(o)[0];a.async=1;a.src=g;m.parentNode.insertBefore(a,m)
      })(window,document,'script','//www.google-analytics.com/analytics.js','ga');
      ga('create', 'UA-50431971-1', 'akirachiku.com');
      ga('send', 'pageview');
    </script>
  </div>
</body>
